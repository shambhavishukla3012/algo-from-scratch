{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_regression_gradient.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo8P2WziANI7"
      },
      "source": [
        "# Import \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import log, dot, e\n",
        "from numpy.random import rand\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YToCUMfZYfk6"
      },
      "source": [
        "# Dataset : self-made dataset\n",
        "df2 = pd.read_excel(\"Logistic.xlsx\")"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "n6z5cihBfOno",
        "outputId": "65db79bb-b8b9-48c5-e599-b32110933fbe"
      },
      "source": [
        "# Remove Last two rows as these are the noise only\n",
        "df2"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.70</td>\n",
              "      <td>68</td>\n",
              "      <td>22</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5.60</td>\n",
              "      <td>67</td>\n",
              "      <td>29</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5.60</td>\n",
              "      <td>52</td>\n",
              "      <td>23</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5.90</td>\n",
              "      <td>80</td>\n",
              "      <td>26</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.50</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>5.00</td>\n",
              "      <td>54</td>\n",
              "      <td>29</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>5.50</td>\n",
              "      <td>70</td>\n",
              "      <td>22</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>5.10</td>\n",
              "      <td>82</td>\n",
              "      <td>25</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>5.20</td>\n",
              "      <td>54</td>\n",
              "      <td>25</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>6.00</td>\n",
              "      <td>73</td>\n",
              "      <td>22</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>5.11</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>5.40</td>\n",
              "      <td>66</td>\n",
              "      <td>30</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>5.80</td>\n",
              "      <td>88</td>\n",
              "      <td>26</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>6.10</td>\n",
              "      <td>83</td>\n",
              "      <td>23</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>5.90</td>\n",
              "      <td>75</td>\n",
              "      <td>27</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>5.60</td>\n",
              "      <td>61</td>\n",
              "      <td>30</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>6.00</td>\n",
              "      <td>82</td>\n",
              "      <td>22</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>5.10</td>\n",
              "      <td>56</td>\n",
              "      <td>36</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>6.10</td>\n",
              "      <td>82</td>\n",
              "      <td>27</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>5.20</td>\n",
              "      <td>66</td>\n",
              "      <td>30</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>5.60</td>\n",
              "      <td>66</td>\n",
              "      <td>24</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>5.70</td>\n",
              "      <td>78</td>\n",
              "      <td>26</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>5.50</td>\n",
              "      <td>54</td>\n",
              "      <td>25</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>5.90</td>\n",
              "      <td>70</td>\n",
              "      <td>28</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>5.80</td>\n",
              "      <td>60</td>\n",
              "      <td>26</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sample  Height  Weight  Age  Gender\n",
              "0        1    5.70      68   22    Male\n",
              "1        2    5.60      67   29    Male\n",
              "2        3    5.60      52   23  Female\n",
              "3        4    5.90      80   26    Male\n",
              "4        5    5.50      70   30    Male\n",
              "5        6    5.00      54   29  female\n",
              "6        7    5.50      70   22    Male\n",
              "7        8    5.10      82   25    male\n",
              "8        9    5.20      54   25  female\n",
              "9       10    6.00      73   22    Male\n",
              "10      11    5.11      79   25    male\n",
              "11      12    5.40      66   30  female\n",
              "12      13    5.80      88   26    male\n",
              "13      14    6.10      83   23    male\n",
              "14      15    5.90      75   27    Male\n",
              "15      16    5.60      61   30  Female\n",
              "16      17    6.00      82   22    Male\n",
              "17      18    5.10      56   36    Male\n",
              "18      19    6.10      82   27    Male\n",
              "19      20    5.20      66   30  female\n",
              "20      21    5.60      66   24  Female\n",
              "21      22    5.70      78   26    Male\n",
              "22      23    5.50      54   25  Female\n",
              "23      24    5.90      70   28  Female\n",
              "24      25    5.80      60   26    Male"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJR7NVdhjAWc"
      },
      "source": [
        "df2.Weight = df2.Weight.astype(float)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaohAtbJyGsT",
        "outputId": "dcd3a24b-4a0a-4ac7-fa32-3199f0be72a6"
      },
      "source": [
        "# Convert Gender column data type as String for easy Processing in next step.\n",
        "df2.Gender.astype(str)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Male\n",
              "1       Male\n",
              "2     Female\n",
              "3       Male\n",
              "4       Male\n",
              "5     female\n",
              "6       Male\n",
              "7       male\n",
              "8     female\n",
              "9       Male\n",
              "10      male\n",
              "11    female\n",
              "12      male\n",
              "13      male\n",
              "14      Male\n",
              "15    Female\n",
              "16      Male\n",
              "17      Male\n",
              "18      Male\n",
              "19    female\n",
              "20    Female\n",
              "21      Male\n",
              "22    Female\n",
              "23    Female\n",
              "24      Male\n",
              "Name: Gender, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqGfKKl-yUAg"
      },
      "source": [
        "# Make all wordds in gender column of same case, let it be Upper Case\n",
        "df2['Gender'] = df2['Gender'].apply(lambda x: x.upper())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_qnXU5_r_I8"
      },
      "source": [
        "LE = LabelEncoder()\n",
        "df2['Gender'] = LE.fit_transform(df2['Gender'])\n",
        "\n",
        "# 1 = Male\n",
        "# 0 = Female"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZDF_fqKyQYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f68d2b-7198-4dcf-86ec-6fa539c15f11"
      },
      "source": [
        "# Now need to convert all data items of Gender to float type\n",
        "df2.gender = df2.Gender.astype(float)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9BVXPAQfmWc"
      },
      "source": [
        "X = df2[['Height','Weight']]\n",
        "y = df2['Gender']\n",
        "\n",
        "# in X - independent variables\n",
        "# one more column of 1's is added\n",
        "# to consider intercept value in weight matrix as weight\n",
        "X = np.c_[np.ones((X.shape[0], 1)), X]"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7bO2qlcMuc"
      },
      "source": [
        "y = (coefficients).Transpose * (varaibles)\n",
        "\n",
        "as intercept is coefficient without any associated variable.   \n",
        "so to include that column of 1's is added in the variable matrix.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAD2iFCASwXR"
      },
      "source": [
        "Model Training\n",
        "\n",
        "Model training is essentially minimization of the loss function. \n",
        "Loss function is Binary Cross-Entropy Loss Function  \n",
        "We achieve that with the Gradient Descent technique, which can be broken into a few steps:\n",
        "\n",
        "1. First, we find derivatives of the loss function with respect to each weight. Derivatives can tell which direction and by how much we should change weight to make the model loss a bit smaller.  \n",
        "2. Updating each weight according to derivative until the local minimum is found, i.e. model doesn’t improve anymore so we can stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yewmXsCeLXL4"
      },
      "source": [
        "class LogisticRegression:\n",
        "    \n",
        "    def sigmoid(self, z): return 1 / (1 + e**(-z))\n",
        "    \n",
        "    # log loss\n",
        "    def cost_function(self, X, y, weights):                 \n",
        "        z = dot(X, weights)\n",
        "        predict_1 = y * log(self.sigmoid(z))\n",
        "        predict_0 = (1 - y) * log(1 - self.sigmoid(z))\n",
        "        return -sum(predict_1 + predict_0) / len(X)\n",
        "    \n",
        "    # epochs = iterations\n",
        "    def fit(self, X, y, epochs=100, lr=0.05):        \n",
        "        loss = []\n",
        "\n",
        "        weights = rand(X.shape[1])  # select weights.no_of_column = X.no_of_column\n",
        "        N = len(X)\n",
        "                 \n",
        "        for _ in range(epochs):        \n",
        "            # Gradient Descent\n",
        "            # X and weights are two matrix that are model_selectors and x variables respectively\n",
        "            y_hat = self.sigmoid(dot(X, weights))\n",
        "            weights -= lr * dot(X.T,  y_hat - y) / N            \n",
        "            # Saving Progress\n",
        "            loss.append(self.cost_function(X, y, weights)) \n",
        "        self.weights = weights\n",
        "        self.loss = loss\n",
        "        return self.loss\n",
        "    \n",
        "    def predict(self, X):        \n",
        "        # Predicting with sigmoid function\n",
        "        z = dot(X, self.weights)\n",
        "        # Returning binary result\n",
        "        # if value is greater than 0.5 - it belongs to class value 1 \n",
        "        # and if less than belongs to class value 0\n",
        "        return [1 if i > 0.5 else 0 for i in self.sigmoid(z)]"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2vr9zXLQX9s"
      },
      "source": [
        "p = LogisticRegression()\n",
        "a = p.fit(X_train,y_train, epochs=200, lr=0.002)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJyJbb2fR3zc"
      },
      "source": [
        "y_pred = p.predict(X_test)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "JUphaNPXYPcp",
        "outputId": "813a56f6-575c-4a49-83d9-c58e7d70968b"
      },
      "source": [
        "# Loss for each iteration\n",
        "plt.plot(a)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd1d0f6a2d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4knouVHSDgZ",
        "outputId": "5c5f98db-26f2-4825-e54d-528aca2144ab"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      0.25      0.33         4\n",
            "\n",
            "    accuracy                           0.20         5\n",
            "   macro avg       0.25      0.12      0.17         5\n",
            "weighted avg       0.40      0.20      0.27         5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}